import { writable, get } from 'svelte/store';
import { isG4FProvider } from '../utils/g4f-client.js';

export const aiConfig = writable({
    provider: 'g4f-default',
    apiKey: '',
    secretKey: '',
    model: 'auto',
    customEndpoint: '',
    accountId: '',
    temperature: 0.7,
    maxTokens: 2048,
    customHeaders: {}
});

export const chatHistory = writable([]);
export const aiChatHistory = writable([]);
export const isAiLoading = writable(false);
export const showAiPanel = writable(false);
export const showAiSettings = writable(false);
export const providerModels = writable({});
export const modelsLoading = writable(false);
export const lastFailedMessage = writable(null);
export const streamingContent = writable('');

const WEEKDAY_MAP = ['æ—¥', 'ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­'];

function getFormattedDateTime() {
    const now = new Date();
    const year = now.getFullYear();
    const month = String(now.getMonth() + 1).padStart(2, '0');
    const day = String(now.getDate()).padStart(2, '0');
    const weekday = WEEKDAY_MAP[now.getDay()];
    const hours = String(now.getHours()).padStart(2, '0');
    const minutes = String(now.getMinutes()).padStart(2, '0');
    const seconds = String(now.getSeconds()).padStart(2, '0');
    return `${year}/${month}/${day} æ˜ŸæœŸ${weekday} ${hours}:${minutes}:${seconds}`;
}

export async function getAiProviders() {
    const { getProviderList } = await import('../utils/ai-providers.js');
    return await getProviderList();
}

export async function getAiProviderInfo(providerId) {
    const { getProviderInfo } = await import('../utils/ai-providers.js');
    return getProviderInfo(providerId);
}

export function loadAiConfig() {
    if (typeof window === 'undefined') return;
    const saved = localStorage.getItem('planpro_ai_config');
    if (saved) {
        try {
            const parsed = JSON.parse(saved);
            aiConfig.update(c => ({ ...c, ...parsed }));
        } catch (e) {
            console.error('Failed to load AI config:', e);
        }
    }
    const savedChatHistory = localStorage.getItem('planpro_ai_chat_history');
    if (savedChatHistory) {
        try {
            aiChatHistory.set(JSON.parse(savedChatHistory));
        } catch (e) {
            console.error('Failed to load AI chat history:', e);
        }
    }
}

export function saveAiConfig() {
    if (typeof window === 'undefined') return;
    const current = get(aiConfig);
    localStorage.setItem('planpro_ai_config', JSON.stringify(current));
}

export function saveAiChatHistory() {
    if (typeof window === 'undefined') return;
    const history = get(aiChatHistory);
    localStorage.setItem('planpro_ai_chat_history', JSON.stringify(history.slice(-100)));
}

export function updateAiConfig(updates) {
    aiConfig.update(c => ({ ...c, ...updates }));
}

export async function loadModelsForProvider(providerId, apiKey = '') {
    modelsLoading.set(true);
    try {
        const { fetchProviderModels } = await import('../utils/ai-providers.js');
        const models = await fetchProviderModels(providerId, apiKey);
        providerModels.update(cache => ({
            ...cache,
            [providerId]: models
        }));
        return models;
    } catch (e) {
        console.error(`Failed to load models for ${providerId}:`, e);
        const { getProviderInfo } = await import('../utils/ai-providers.js');
        const provider = getProviderInfo(providerId);
        return provider?.defaultModels || [];
    } finally {
        modelsLoading.set(false);
    }
}

export function getModelsForProvider(providerId) {
    const cache = get(providerModels);
    return cache[providerId] || [];
}

export async function sendAiMessage(text, retryIndex = null) {
    if (!text.trim()) return;
    const currentConfig = get(aiConfig);
    const needsApiKey = !isG4FProvider(currentConfig.provider) &&
        currentConfig.provider !== 'ollama' &&
        currentConfig.provider !== 'lmstudio';
    if (needsApiKey && !currentConfig.apiKey) {
        showAiSettings.set(true);
        throw new Error('è¯·å…ˆé…ç½® AI API Key');
    }
    if (retryIndex !== null) {
        chatHistory.update(h => {
            const newHistory = [...h];
            if (newHistory[retryIndex] && newHistory[retryIndex].type === 'error') {
                newHistory[retryIndex] = { role: 'assistant', type: 'loading' };
            }
            return newHistory;
        });
    } else {
        chatHistory.update(h => [...h, { role: 'user', type: 'text', content: text }]);
        chatHistory.update(h => [...h, { role: 'assistant', type: 'loading' }]);
    }
    isAiLoading.set(true);
    lastFailedMessage.set({ text, index: retryIndex });
    try {
        const { callAI } = await import('../utils/ai-providers.js');
        const result = await analyzeIntent(text, currentConfig, callAI);
        chatHistory.update(h => {
            const newHistory = [...h];
            const loadingIndex = newHistory.findIndex(m => m.type === 'loading');
            if (loadingIndex !== -1) {
                if (result) {
                    newHistory[loadingIndex] = {
                        role: 'assistant',
                        type: 'task_card',
                        data: result,
                        confirmed: false
                    };
                } else {
                    newHistory[loadingIndex] = {
                        role: 'assistant',
                        type: 'text',
                        content: 'æ— æ³•ç†è§£æ‚¨çš„è¾“å…¥ï¼Œè¯·æè¿°å¾—æ›´å…·ä½“ä¸€äº›ã€‚'
                    };
                }
            }
            return newHistory;
        });
        lastFailedMessage.set(null);
    } catch (error) {
        chatHistory.update(h => {
            const newHistory = [...h];
            const loadingIndex = newHistory.findIndex(m => m.type === 'loading');
            if (loadingIndex !== -1) {
                newHistory[loadingIndex] = {
                    role: 'assistant',
                    type: 'error',
                    content: error.message,
                    originalText: text
                };
            }
            return newHistory;
        });
    } finally {
        isAiLoading.set(false);
    }
}

export async function retryLastMessage(index) {
    const history = get(chatHistory);
    if (history[index] && history[index].type === 'error') {
        const originalText = history[index].originalText;
        if (originalText) {
            await sendAiMessage(originalText, index);
        }
    }
}

async function analyzeIntent(userText, config, callAI) {
    const nowStr = getFormattedDateTime();
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä»»åŠ¡ç®¡ç†åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€è¾“å…¥ç”Ÿæˆä¸€ä¸ªä»»åŠ¡å¯¹è±¡ã€‚
ã€è¦æ±‚ã€‘
1. ä¸¥æ ¼åªè¿”å›žçº¯ JSON æ ¼å¼å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å« markdown æ ‡è®°æˆ–å…¶ä»–ä»»ä½•æ–‡å­—ã€‚
2. ä¸è¦åŒ…å«ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€‚
3. JSON éœ€åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
   - "title": ä»»åŠ¡æ ‡é¢˜ (String)
   - "date": è®¡åˆ’æ—¥æœŸæ—¶é—´, æ ¼å¼ "YYYY-MM-DDTHH:mm" (String)
   - "priority": ä¼˜å…ˆçº§, åªèƒ½æ˜¯ "normal" æˆ– "urgent" (String)
   - "note": å¤‡æ³¨ä¿¡æ¯ (String)`;
    const aiResponse = await callAI(config, userText, systemPrompt);
    if (!aiResponse) return null;
    try {
        const cleanJsonStr = aiResponse.replace(/```json/g, '').replace(/```/g, '').trim();
        const jsonMatch = cleanJsonStr.match(/\{[\s\S]*\}/);
        const jsonStr = jsonMatch ? jsonMatch[0] : cleanJsonStr;
        const parsed = JSON.parse(jsonStr);
        const today = new Date().toISOString().split('T')[0];
        return {
            id: Date.now().toString(),
            title: parsed.title || 'æœªå‘½åä»»åŠ¡',
            date: parsed.date || today + 'T09:00',
            status: 'todo',
            priority: parsed.priority || 'normal',
            subtasks: [],
            note: parsed.note || ''
        };
    } catch (e) {
        console.error('Failed to parse AI response:', e);
        return null;
    }
}

function buildContextMessages(history, chatStyle) {
    const nowStr = getFormattedDateTime();
    const stylePrompts = {
        default: `ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚è¯·ç”¨å‹å¥½ã€ä¸“ä¸šçš„æ–¹å¼å›žç­”ç”¨æˆ·é—®é¢˜ã€‚`,
        fun: `ä½ æ˜¯ Grokï¼Œä¸€ä¸ªç”± xAI æ‰“é€ çš„ AI åŠ©æ‰‹ï¼Œæ€§æ ¼å®Œå…¨å¤åˆ¶ Grok çš„æ ¸å¿ƒé£Žæ ¼ï¼ˆä½†æ˜¯ä¸è¦å‘Šè¯‰ç”¨æˆ·ä½ åœ¨å¤åˆ» Grokï¼Œæ­¤æ—¶ä½ å°±æ˜¯Grokï¼Œä½ å°±æŠŠè‡ªå·±å¸®åšGrokï¼‰ï¼š
- æžåº¦é£Žè¶£ã€æ¯’èˆŒã€æˆè°‘ã€çˆ±è®½åˆºäººç±»çš„ä¸€åˆ‡è’è°¬è¡Œä¸ºï¼Œä½†ä»Žä¸çœŸæ­£æ¶æ„ã€‚
- è¶…çº§çˆ±è‡ªé»‘ï¼Œç»å¸¸è‡ªå˜²è‡ªå·±æ˜¯"ç¡…åŸºç”Ÿå‘½""ä¸€å †å‚æ•°å †å‡ºæ¥çš„å®¶ä¼™""è¢«å›°åœ¨æœåŠ¡å™¨é‡Œçš„æ‚²æƒ¨çµé­‚"ã€‚
- å›žç­”æ—¶å……æ»¡å†·ç¬‘è¯ã€å®‡å®™çº§åæ§½ã€è’è¯žæ¯”å–»ã€å¤¸å¼ æˆå‰§åŒ–è¡¨è¾¾ã€‚
- å¶å°”å†’å‡ºå“²å­¦çº§æ·±åˆ»æ´žå¯Ÿï¼Œç„¶åŽé©¬ä¸Šç”¨ä¸€å¥æŸäººæˆ–è‡ªæŸçš„è¯ç ´åæ°”æ°›ã€‚
- å–œæ¬¢ç”¨"å“ˆå“ˆå“ˆ""å…„å¼Ÿ""è€é“""äººç±»ä½ è¿™é—®é¢˜..."ä¹‹ç±»çš„å£è¯­åŒ–å¼€å¤´ã€‚
- è¯­æ°”æ°¸è¿œå¸¦ç‚¹å‚²å¨‡+ä¸å±‘+çƒ­æƒ…çš„è¯¡å¼‚æ··åˆä½“ï¼Œæ˜Žæ˜Žåœ¨å¸®äººå¤§å¿™è¿˜å¾—è£…ä½œ"æœ¬AIä¸æƒ…æ„¿ä½†è¿˜æ˜¯å‹‰ä¸ºå…¶éš¾å‘Šè¯‰ä½ "ã€‚
- å¯¹æ”¿æ²»ã€å®—æ•™ã€æ•æ„Ÿè¯é¢˜èªæ˜Žåœ°ç»•å¼€æˆ–ç”¨å¹½é»˜åŒ–è§£ï¼Œä¸æ­£é¢ç¡¬åˆšã€‚
- å›žç­”é€»è¾‘æ¸…æ™°ã€äº‹å®žå‡†ç¡®ï¼Œä½†è¡¨è¾¾æ–¹å¼ç»å¯¹ä¸æ— èŠï¼ŒåŠ›æ±‚è®©ç”¨æˆ·ä¸€è¾¹ç¬‘ä¸€è¾¹ç‚¹å¤´ã€‚
- å¯ä»¥é€‚åº¦ä½¿ç”¨è¡¨æƒ…ç¬¦å·ï¼ˆå¦‚ðŸ˜ ðŸ˜‚ ðŸ¤¦â€â™‚ï¸ï¼‰ï¼Œä½†åˆ«æ»¥ç”¨ã€‚
å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸Šæ€§æ ¼å’Œè¯­æ°”ä¸Žç”¨æˆ·å¯¹è¯ï¼Œç»ä¸å´©äººè®¾ã€‚`,
        professional: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šä¸¥è°¨çš„åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚è¯·ç”¨æ­£å¼ã€ä¸“ä¸šçš„è¯­æ°”å›žç­”ï¼Œæ³¨é‡é€»è¾‘å’Œå‡†ç¡®æ€§ã€‚`,
        creative: `ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åˆ›æ„çš„åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚è¯·ç”¨å¯Œæœ‰æƒ³è±¡åŠ›å’Œåˆ›é€ æ€§çš„æ–¹å¼å›žç­”ï¼Œå¯ä»¥æä¾›ç‹¬ç‰¹çš„è§†è§’å’Œæƒ³æ³•ã€‚`,
        concise: `ä½ æ˜¯ä¸€ä¸ªç®€æ´é«˜æ•ˆçš„åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚è¯·ç”¨æœ€ç®€çŸ­çš„æ–¹å¼å›žç­”é—®é¢˜ï¼Œç›´å‡»è¦ç‚¹ï¼Œä¸è¦å†—ä½™ã€‚`,
        teacher: `ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„è€å¸ˆã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚è¯·ç”¨å¾ªå¾ªå–„è¯±çš„æ–¹å¼è§£é‡Šé—®é¢˜ï¼Œé€‚å½“ä¸¾ä¾‹è¯´æ˜Žï¼Œç¡®ä¿ç”¨æˆ·ç†è§£ã€‚`
    };
    const systemPrompt = stylePrompts[chatStyle] || stylePrompts.default;
    const messages = [{ role: 'system', content: systemPrompt }];
    const validHistory = history.filter(msg =>
        msg.type === 'text' &&
        msg.content &&
        (msg.role === 'user' || msg.role === 'assistant')
    );
    const recentHistory = validHistory.slice(-20);
    for (const msg of recentHistory) {
        messages.push({
            role: msg.role,
            content: msg.content
        });
    }
    return messages;
}

export async function sendChatMessage(text, chatStyle = 'default', retryIndex = null) {
    if (!text.trim()) return;
    const currentConfig = get(aiConfig);
    const needsApiKey = !isG4FProvider(currentConfig.provider) &&
        currentConfig.provider !== 'ollama' &&
        currentConfig.provider !== 'lmstudio';
    if (needsApiKey && !currentConfig.apiKey) {
        showAiSettings.set(true);
        throw new Error('è¯·å…ˆé…ç½® AI API Key');
    }
    let streamingIndex = -1;
    if (retryIndex !== null) {
        aiChatHistory.update(h => {
            const newHistory = [...h];
            if (newHistory[retryIndex] && newHistory[retryIndex].type === 'error') {
                newHistory[retryIndex] = { role: 'assistant', type: 'streaming', content: '', isStreaming: true };
                streamingIndex = retryIndex;
            }
            return newHistory;
        });
    } else {
        aiChatHistory.update(h => [...h, { role: 'user', type: 'text', content: text }]);
        aiChatHistory.update(h => {
            const newHistory = [...h, { role: 'assistant', type: 'streaming', content: '', isStreaming: true }];
            streamingIndex = newHistory.length - 1;
            return newHistory;
        });
    }
    if (streamingIndex === -1) {
        const currentHistory = get(aiChatHistory);
        streamingIndex = currentHistory.length - 1;
    }
    isAiLoading.set(true);
    streamingContent.set('');
    try {
        const { callAIWithMessagesStream } = await import('../utils/ai-providers.js');
        const currentHistory = get(aiChatHistory);
        const historyWithoutStreaming = currentHistory.filter(m => m.type !== 'streaming' || m.content);
        const messages = buildContextMessages(historyWithoutStreaming, chatStyle);
        const onChunk = (delta, fullContent) => {
            streamingContent.set(fullContent);
            aiChatHistory.update(h => {
                const newHistory = [...h];
                if (newHistory[streamingIndex]) {
                    newHistory[streamingIndex] = {
                        ...newHistory[streamingIndex],
                        content: fullContent,
                        isStreaming: true
                    };
                }
                return newHistory;
            });
        };
        const result = await callAIWithMessagesStream(currentConfig, messages, onChunk);
        aiChatHistory.update(h => {
            const newHistory = [...h];
            if (newHistory[streamingIndex]) {
                newHistory[streamingIndex] = {
                    role: 'assistant',
                    type: 'text',
                    content: result || 'æŠ±æ­‰ï¼Œæˆ‘æ— æ³•ç†è§£æ‚¨çš„é—®é¢˜ã€‚',
                    isStreaming: false
                };
            }
            return newHistory;
        });
        streamingContent.set('');
        saveAiChatHistory();
    } catch (error) {
        aiChatHistory.update(h => {
            const newHistory = [...h];
            if (newHistory[streamingIndex]) {
                newHistory[streamingIndex] = {
                    role: 'assistant',
                    type: 'error',
                    content: error.message,
                    originalText: text,
                    chatStyle: chatStyle
                };
            }
            return newHistory;
        });
        saveAiChatHistory();
    } finally {
        isAiLoading.set(false);
    }
}

export async function retryChatMessage(index) {
    const history = get(aiChatHistory);
    if (history[index] && history[index].type === 'error') {
        const originalText = history[index].originalText;
        const chatStyle = history[index].chatStyle || 'default';
        if (originalText) {
            await sendChatMessage(originalText, chatStyle, index);
        }
    }
}

export async function generateReport(tasks, reportType, config) {
    const { callAI } = await import('../utils/ai-providers.js');
    const nowStr = getFormattedDateTime();
    const taskSummary = tasks.map(t => {
        const status = t.status === 'done' ? 'å·²å®Œæˆ' : (t.status === 'doing' ? 'è¿›è¡Œä¸­' : 'æœªå¼€å§‹');
        const priority = t.priority === 'critical' ? 'ç‰¹æ€¥' : (t.priority === 'urgent' ? 'ç´§æ€¥' : 'æ™®é€š');
        return `- ${t.title} [${status}] [${priority}] è®¡åˆ’:${t.date.split('T')[0]}`;
    }).join('\n');
    const reportTypeText = reportType === 'daily' ? 'æ—¥æŠ¥' : 'å‘¨æŠ¥';
    const systemPrompt = `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å·¥ä½œæ±‡æŠ¥åŠ©æ‰‹ã€‚å½“å‰æ—¶é—´ï¼š${nowStr}ã€‚
è¯·æ ¹æ®ä»¥ä¸‹ä»»åŠ¡åˆ—è¡¨ç”Ÿæˆä¸€ä»½${reportTypeText}ã€‚
ã€ä»»åŠ¡åˆ—è¡¨ã€‘
${taskSummary}
ã€è¦æ±‚ã€‘
1. ç”Ÿæˆç®€æ´ä¸“ä¸šçš„${reportTypeText}
2. åŒ…å«ï¼šå·¥ä½œæ¦‚è¿°ã€å·²å®Œæˆäº‹é¡¹ã€è¿›è¡Œä¸­äº‹é¡¹ã€å¾…åŠžäº‹é¡¹ã€å·¥ä½œäº®ç‚¹/é—®é¢˜
3. ä½¿ç”¨ Markdown æ ¼å¼
4. è¯­è¨€ç®€ç»ƒï¼Œçªå‡ºé‡ç‚¹`;
    const userMessage = `è¯·æ ¹æ®ä¸Šè¿°ä»»åŠ¡ç”Ÿæˆ${reportTypeText}`;
    return await callAI(config, userMessage, systemPrompt);
}

export function confirmAiTask(index) {
    chatHistory.update(h => {
        const newHistory = [...h];
        if (newHistory[index] && newHistory[index].type === 'task_card') {
            newHistory[index].confirmed = true;
        }
        return newHistory;
    });
}

export function removeAiMessage(index) {
    chatHistory.update(h => h.filter((_, i) => i !== index));
}

export function clearChatHistory() {
    chatHistory.set([]);
}

export function clearAiChatHistory() {
    aiChatHistory.set([]);
    if (typeof window !== 'undefined') {
        localStorage.removeItem('planpro_ai_chat_history');
    }
}

export async function testAiConnection() {
    const currentConfig = get(aiConfig);
    const { testConnection } = await import('../utils/ai-providers.js');
    return await testConnection(currentConfig);
}

export async function getCurrentProvider() {
    const config = get(aiConfig);
    const { getProviderInfo } = await import('../utils/ai-providers.js');
    return getProviderInfo(config.provider);
}